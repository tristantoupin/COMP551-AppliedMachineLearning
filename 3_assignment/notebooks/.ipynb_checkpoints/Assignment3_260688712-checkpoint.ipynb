{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import grid_search, svm, metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import string\n",
    "from scipy import stats\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../data/\"\n",
    "path_to_gen = \"../generated/\"\n",
    "\n",
    "# paht to imbd\n",
    "imbd_train = \"IMDB-train.txt\"\n",
    "imbd_val = \"IMDB-valid.txt\"\n",
    "imbd_test = \"IMDB-test.txt\"\n",
    "\n",
    "# paht to yelp\n",
    "yelp_train = \"yelp-train.txt\"\n",
    "yelp_val = \"yelp-valid.txt\"\n",
    "yelp_test = \"yelp-test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data as df\n",
    "df_imbd_train = pd.read_csv(path_to_data + imbd_train, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_imbd_test = pd.read_csv(path_to_data + imbd_test, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_imbd_val = pd.read_csv(path_to_data + imbd_val, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "\n",
    "df_yelp_train = pd.read_csv(path_to_data + yelp_train, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_yelp_test = pd.read_csv(path_to_data + yelp_test, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_yelp_val = pd.read_csv(path_to_data + yelp_val, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count frequency of normalized x\n",
    "def normalize_df(e):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    normalizer = lambda x: x.lower().translate(translator) # lower and remove punctuation\n",
    "    return list(filter(None, ' '.join(list(map(normalizer, np.array(e.review)))).split(' ')))\n",
    "\n",
    "def normalize_str(e):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    normalizer = lambda x: x.lower().translate(translator) # lower and remove punctuation\n",
    "    return list(filter(None, list(map(normalizer, e.split(' ')))))\n",
    "    \n",
    "def count_word_frequency(words):\n",
    "    occurence = {}\n",
    "    for w in words:\n",
    "        if w in occurence:\n",
    "            occurence[w] += 1\n",
    "        else:\n",
    "            occurence[w] = 1\n",
    "    return occurence\n",
    "\n",
    "def get_most_n_frequent(data, n = 10000):\n",
    "    normed = normalize_df(data)\n",
    "    count_dict = count_word_frequency(normed)\n",
    "    n_sorted_words = (sorted(count_dict.items(), key=lambda kv: kv[1], reverse = True)[:n])\n",
    "    return [k for k,v in n_sorted_words]\n",
    "    \n",
    "def gen_vec(data, data_train, most_freq):\n",
    "    all_vector_b = []\n",
    "    all_vector_f = []\n",
    "    for review, class_id in tqdm(zip(data.review, data['class']), total = len(data.review)):\n",
    "        vector_b, vector_f = list(np.zeros(10000)), list(np.zeros(10000))\n",
    "        sum_ = 0\n",
    "        norm_rev = normalize_str(review)\n",
    "        for word in norm_rev:\n",
    "            try:\n",
    "                i = most_freq.index(word)\n",
    "                vector_b[i] = 1\n",
    "                vector_f[i] += 1\n",
    "                sum_ += 1\n",
    "            except:\n",
    "                pass\n",
    "        # if no word is recognized\n",
    "        if sum_ == 0:\n",
    "            sum_ = 1\n",
    "        vector_f = [float(e/sum_) for e in vector_f]\n",
    "        vector_b.append(int(class_id))\n",
    "        vector_f.append(int(class_id))\n",
    "        all_vector_b.append(np.array(vector_b))\n",
    "        all_vector_f.append(np.array(vector_f))\n",
    "    \n",
    "    return np.array(all_vector_b).astype(int), np.array(all_vector_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbd_most_freq = get_most_n_frequent(df_imbd_train)\n",
    "yelp_most_freq = get_most_n_frequent(df_yelp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# binary bag-of-words representation\n",
    "df_imbd_train_BBoW, df_imbd_train_FBoW = gen_vec(df_imbd_train, df_imbd_train, imbd_most_freq)\n",
    "df_yelp_train_BBoW, df_yelp_train_FBoW = gen_vec(df_yelp_train, df_yelp_train, yelp_most_freq)\n",
    "df_imbd_test_BBoW, df_imbd_test_FBoW = gen_vec(df_imbd_test, df_imbd_train, imbd_most_freq)\n",
    "df_yelp_test_BBoW, df_yelp_test_FBoW = gen_vec(df_yelp_test, df_yelp_train, yelp_most_freq)\n",
    "df_imbd_val_BBoW, df_imbd_val_FBoW = gen_vec(df_imbd_val, df_imbd_train, imbd_most_freq)\n",
    "df_yelp_val_BBoW, df_yelp_val_FBoW = gen_vec(df_yelp_val, df_yelp_train, yelp_most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframes just created\n",
    "def save_gen(arrays, type_, dataset_name):\n",
    "    # dataframes in order [train, val, test]\n",
    "    suffixes = [\"-train-\", \"-valid-\", \"-test-\"]\n",
    "    for a, s in zip(arrays, suffixes):\n",
    "        np.savetxt(path_to_gen + dataset_name + s + type_ + '.txt', a, fmt='%s')\n",
    "        \n",
    "save_gen([df_imbd_train_BBoW, df_imbd_val_BBoW, df_imbd_test_BBoW], \"BBoW\", \"IMBD\")\n",
    "save_gen([df_yelp_train_BBoW, df_yelp_val_BBoW, df_yelp_test_BBoW], \"BBoW\", \"yelp\")\n",
    "save_gen([df_imbd_train_FBoW, df_imbd_val_FBoW, df_imbd_test_FBoW], \"FBoW\", \"IMBD\")\n",
    "save_gen([df_yelp_train_FBoW, df_yelp_val_FBoW, df_yelp_test_FBoW], \"FBoW\", \"yelp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_train_BBoW = np.loadtxt(path_to_gen + \"IMBD-train-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_train_FBoW = np.loadtxt(path_to_gen + \"IMBD-train-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_train_BBoW = np.loadtxt(path_to_gen + \"yelp-train-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_train_FBoW = np.loadtxt(path_to_gen + \"yelp-train-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_test_BBoW = np.loadtxt(path_to_gen + \"IMBD-test-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_test_FBoW = np.loadtxt(path_to_gen + \"IMBD-test-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_test_BBoW = np.loadtxt(path_to_gen + \"yelp-test-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_test_FBoW = np.loadtxt(path_to_gen + \"yelp-test-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_val_BBoW = np.loadtxt(path_to_gen + \"IMBD-valid-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_val_FBoW = np.loadtxt(path_to_gen + \"IMBD-valid-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_val_BBoW = np.loadtxt(path_to_gen + \"yelp-valid-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_val_FBoW = np.loadtxt(path_to_gen + \"yelp-valid-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Using data from **yelp** created with **BBoW** only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = df_yelp_train_BBoW[:,:-1]\n",
    "y_tr = df_yelp_train_BBoW[:,-1]\n",
    "\n",
    "x_val = df_yelp_val_BBoW[:,:-1]\n",
    "y_val = df_yelp_val_BBoW[:,-1]\n",
    "\n",
    "x_test = df_yelp_test_BBoW[:,:-1]\n",
    "y_test = df_yelp_test_BBoW[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_random_clf(x_tr, y_tr, x_test, y_test, r = 1234):\n",
    "    clf = DummyClassifier(strategy = 'uniform', random_state = r)\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    preds = clf.predict(x_test)\n",
    "    f1 = metrics.f1_score(y_test, preds, average = 'micro')\n",
    "    return f1\n",
    "    \n",
    "def performance_majority_classifier(x_tr, y_tr, x_test, y_test, r = 1234):\n",
    "    most_common_val = stats.mode(y_tr).mode[0]\n",
    "    preds = np.full((y_test.shape), most_common_val)\n",
    "    f1 = metrics.f1_score(y_test, preds, average = 'micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_random = performance_random_clf(x_tr, y_tr, x_test, y_test)\n",
    "baseline_majority = performance_majority_classifier(x_tr, y_tr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance for the random classifier on the Yelp reviews dataset created with BBoW is 0.1975.\n",
      "The performance for the majority classifier on the Yelp reviews dataset created with BBoW is 0.351.\n"
     ]
    }
   ],
   "source": [
    "print(\"The performance for the random classifier on the Yelp \" + \n",
    "      \"reviews dataset created with BBoW is %s.\" % baseline_random)\n",
    "print(\"The performance for the majority classifier on the Yelp \" +\n",
    "      \"reviews dataset created with BBoW is %s.\" % baseline_majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fine_tune = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_bernoulli_naive_bayes(x_tr, y_tr, x_val, y_val, number_of_model, alphas):\n",
    "    all_as = random.choices(list(np.linspace(alphas[0],\n",
    "                                             alphas[1],\n",
    "                                             number_of_model*100, endpoint=True)),\n",
    "                            k=number_of_model)\n",
    "    f1_scores = []\n",
    "    best_model = None\n",
    "    for a in tqdm(all_as):\n",
    "        model = BernoulliNB(alpha = a)\n",
    "        model.fit(x_tr, y_tr)\n",
    "        preds = model.predict(x_val)\n",
    "        cur_f1 = metrics.f1_score(y_val, preds, average = 'micro')\n",
    "        f1_scores.append(cur_f1)\n",
    "        if cur_f1 == max(f1_scores):\n",
    "            best_model = model\n",
    "    print(\"The best f1 score is:\", max(f1_scores))\n",
    "    print(\"The alpha is set to:\", best_model.get_params()['alpha'])\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_decision_tree_classifier(x_tr, y_tr, x_val, y_val,\n",
    "                                       number_of_model, max_depths,\n",
    "                                       min_samples_split, min_samples_leaf):\n",
    "    \n",
    "    all_md = random.choices(list(np.linspace(max_depths[0],\n",
    "                                             max_depths[1],\n",
    "                                             number_of_model*100, endpoint=True)),\n",
    "                            k=number_of_model)\n",
    "    \n",
    "    all_mss = random.choices(list(np.linspace(min_samples_split[0],\n",
    "                                              min_samples_split[1],\n",
    "                                              number_of_model*100, endpoint=True)),\n",
    "                             k=number_of_model)\n",
    "\n",
    "    all_msl = random.choices(list(np.linspace(min_samples_leaf[0],\n",
    "                                              min_samples_leaf[1],\n",
    "                                              number_of_model*100, endpoint=True)),\n",
    "                             k=number_of_model)\n",
    "\n",
    "    f1_scores = []\n",
    "    best_model = None\n",
    "    for md, mss, msl in tqdm(zip(all_md, all_mss, all_msl), total=number_of_model):\n",
    "        model = DecisionTreeClassifier(max_depth=md, min_samples_split=mss, min_samples_leaf=msl)\n",
    "        model.fit(x_tr, y_tr)\n",
    "        preds = model.predict(x_val)\n",
    "        cur_f1 = metrics.f1_score(y_val, preds, average = 'micro')\n",
    "        f1_scores.append(cur_f1)\n",
    "        if cur_f1 == max(f1_scores):\n",
    "            best_model = model\n",
    "    print(\"The best f1 score is:\", max(f1_scores))\n",
    "    print(\"The max depth is set to:\", best_model.get_params()['max_depth'])\n",
    "    print(\"The min samples split is set to:\", best_model.get_params()['min_samples_split'])\n",
    "    print(\"The min samples leaf is set to:\", best_model.get_params()['min_samples_leaf'])\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_linear_SVM(x_tr, y_tr, x_val, y_val,\n",
    "                         number_of_model, cs, gammas):\n",
    "    all_c = random.choices(list(np.linspace(cs[0], cs[1],\n",
    "                                            number_of_model*100, endpoint=True)), \n",
    "                           k=number_of_model)\n",
    "    \n",
    "    all_g = random.choices(list(np.linspace(gammas[0], gammas[1],\n",
    "                                            number_of_model*100, endpoint=True)), \n",
    "                           k=number_of_model)\n",
    "    print(all_c)\n",
    "    print(all_g)\n",
    "    f1_scores = []\n",
    "    best_model = None\n",
    "    for c, gamma in tqdm(zip(all_c, all_g), total=number_of_model):\n",
    "        model = svm.SVC(C=c, gamma=gamma)\n",
    "        model.fit(x_tr[:100], y_tr[:100])\n",
    "        preds = model.predict(x_val[:100])\n",
    "        cur_f1 = metrics.f1_score(y_val[:100], preds, average = 'micro')\n",
    "        f1_scores.append(cur_f1)\n",
    "        if cur_f1 == max(f1_scores):\n",
    "            best_model = model\n",
    "    print(\"The best f1 score is:\", max(f1_scores))\n",
    "    print(\"The c is set to:\", best_model.get_params()['C'])\n",
    "    print(\"The gamma is set to:\", best_model.get_params()['gamma'])\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fine_tune_bernoulli_naive_bayes(x_tr, y_tr, x_val, y_val, n_fine_tune, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_decision_tree_classifier(x_tr, y_tr, x_val, y_val, n_fine_tune, [1, 32], [0.1, 1.0], [0.1, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_linear_SVM(x_tr, y_tr, x_val, y_val, n_fine_tune, [0.001, 10], [0.001, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = df_yelp_train_FBoW[:,:-1]\n",
    "y_tr = df_yelp_train_FBoW[:,-1]\n",
    "\n",
    "x_val = df_yelp_val_FBoW[:,:-1]\n",
    "y_val = df_yelp_val_FBoW[:,-1]\n",
    "\n",
    "x_test = df_yelp_test_FBoW[:,:-1]\n",
    "y_test = df_yelp_test_FBoW[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan, ...,  nan,  nan,   1.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp_train_FBoW[3615]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_gaussian_naive_bayes(x_tr, y_tr, x_val, y_val, number_of_model, vars_smoothing):\n",
    "    all_vs = random.choices(list(np.linspace(vars_smoothing[0],\n",
    "                                             vars_smoothing[1],\n",
    "                                             number_of_model*100, endpoint=True)),\n",
    "                            k=number_of_model)\n",
    "    f1_scores = []\n",
    "    best_model = None\n",
    "    for vs in tqdm(all_vs):\n",
    "        model = GaussianNB()\n",
    "        print(model)\n",
    "        print(x_tr.flatten().shape)\n",
    "        print(x_tr.flatten()[36150000])\n",
    "        print(np.argmax(x_tr))\n",
    "        model.fit(x_tr, y_tr)\n",
    "        preds = model.predict(x_val)\n",
    "        cur_f1 = metrics.f1_score(y_val, preds, average = 'micro')\n",
    "        f1_scores.append(cur_f1)\n",
    "        if cur_f1 == max(f1_scores):\n",
    "            best_model = model\n",
    "    print(\"The best f1 score is:\", max(f1_scores))\n",
    "    print(\"The alpha is set to:\", best_model.get_params()['var_smoothing'])\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12842563b15a4acab92c66ae4dae7e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "(70000000,)\n",
      "nan\n",
      "36150000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-23e4a92e4cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfine_tune_gaussian_naive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fine_tune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1e-12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-ba2b077c8a14>\u001b[0m in \u001b[0;36mfine_tune_gaussian_naive_bayes\u001b[0;34m(x_tr, y_tr, x_val, y_val, number_of_model, vars_smoothing)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m36150000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcur_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mWeights\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mindividual\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munweighted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m                \u001b[0mGaussian\u001b[0m \u001b[0mNaive\u001b[0m \u001b[0mBayes\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mfitting\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[1;32m    575\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# accept_sparse 'None' deprecation check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         warnings.warn(\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0;34m\"Passing 'None' to parameter 'accept_sparse' in methods \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;34m\"check_array and check_X_y is deprecated in version 0.19 \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'assume_finite'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;31m# First try an O(n) time, O(1) space solution for the common case that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# everything is finite; fall back to O(n) space np.isfinite to prevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "fine_tune_gaussian_naive_bayes(x_tr, y_tr, x_val, y_val, n_fine_tune, [1e-12, 1e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
