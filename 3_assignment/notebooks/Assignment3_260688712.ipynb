{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import sklearn.naive_bayes\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import string\n",
    "from scipy import stats\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../data/\"\n",
    "path_to_gen = \"../generated/\"\n",
    "\n",
    "# paht to imbd\n",
    "imbd_train = \"IMDB-train.txt\"\n",
    "imbd_val = \"IMDB-valid.txt\"\n",
    "imbd_test = \"IMDB-test.txt\"\n",
    "\n",
    "# paht to yelp\n",
    "yelp_train = \"yelp-train.txt\"\n",
    "yelp_val = \"yelp-valid.txt\"\n",
    "yelp_test = \"yelp-test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data as df\n",
    "df_imbd_train = pd.read_csv(path_to_data + imbd_train, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_imbd_test = pd.read_csv(path_to_data + imbd_test, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_imbd_val = pd.read_csv(path_to_data + imbd_val, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "\n",
    "df_yelp_train = pd.read_csv(path_to_data + yelp_train, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_yelp_test = pd.read_csv(path_to_data + yelp_test, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_yelp_val = pd.read_csv(path_to_data + yelp_val, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count frequency of normalized x\n",
    "def normalize_df(e):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    normalizer = lambda x: x.lower().translate(translator) # lower and remove punctuation\n",
    "    return list(filter(None, ' '.join(list(map(normalizer, np.array(e.review)))).split(' ')))\n",
    "\n",
    "def normalize_str(e):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    normalizer = lambda x: x.lower().translate(translator) # lower and remove punctuation\n",
    "    return list(filter(None, list(map(normalizer, e.split(' ')))))\n",
    "    \n",
    "def count_word_frequency(words):\n",
    "    occurence = {}\n",
    "    for w in words:\n",
    "        if w in occurence:\n",
    "            occurence[w] += 1\n",
    "        else:\n",
    "            occurence[w] = 1\n",
    "    return occurence\n",
    "\n",
    "def get_most_n_frequent(data, n = 10000):\n",
    "    normed = normalize_df(data)\n",
    "    count_dict = count_word_frequency(normed)\n",
    "    n_sorted_words = (sorted(count_dict.items(), key=lambda kv: kv[1], reverse = True)[:n])\n",
    "    return [k for k,v in n_sorted_words]\n",
    "    \n",
    "def gen_vec(data, data_train, most_freq):\n",
    "    all_vector_b = []\n",
    "    all_vector_f = []\n",
    "    for review, class_id in tqdm(zip(data.review, data['class']), total = len(data.review)):\n",
    "        vector_b, vector_f = list(np.zeros(10000)), list(np.zeros(10000))\n",
    "        sum_ = 0\n",
    "        norm_rev = normalize_str(review)\n",
    "        for word in norm_rev:\n",
    "            try:\n",
    "                i = most_freq.index(word)\n",
    "                vector_b[i] = 1\n",
    "                vector_f[i] += 1\n",
    "                sum_ += 1\n",
    "            except:\n",
    "                pass\n",
    "        # if no word is recognized\n",
    "        if sum_ == 0:\n",
    "            sum_ = 1\n",
    "        vector_f = [float(e/sum_) for e in vector_f]\n",
    "        vector_b.append(int(class_id))\n",
    "        vector_f.append(int(class_id))\n",
    "        all_vector_b.append(np.array(vector_b))\n",
    "        all_vector_f.append(np.array(vector_f))\n",
    "    \n",
    "    return np.array(all_vector_b).astype(int), np.array(all_vector_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbd_most_freq = get_most_n_frequent(df_imbd_train)\n",
    "yelp_most_freq = get_most_n_frequent(df_yelp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# binary bag-of-words representation\n",
    "df_imbd_train_BBoW, df_imbd_train_FBoW = gen_vec(df_imbd_train, df_imbd_train, imbd_most_freq)\n",
    "df_yelp_train_BBoW, df_yelp_train_FBoW = gen_vec(df_yelp_train, df_yelp_train, yelp_most_freq)\n",
    "df_imbd_test_BBoW, df_imbd_test_FBoW = gen_vec(df_imbd_test, df_imbd_train, imbd_most_freq)\n",
    "df_yelp_test_BBoW, df_yelp_test_FBoW = gen_vec(df_yelp_test, df_yelp_train, yelp_most_freq)\n",
    "df_imbd_val_BBoW, df_imbd_val_FBoW = gen_vec(df_imbd_val, df_imbd_train, imbd_most_freq)\n",
    "df_yelp_val_BBoW, df_yelp_val_FBoW = gen_vec(df_yelp_val, df_yelp_train, yelp_most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframes just created\n",
    "def save_gen(arrays, type_, dataset_name):\n",
    "    # dataframes in order [train, val, test]\n",
    "    suffixes = [\"-train-\", \"-valid-\", \"-test-\"]\n",
    "    for a, s in zip(arrays, suffixes):\n",
    "        np.savetxt(path_to_gen + dataset_name + s + type_ + '.txt', a, fmt='%s')\n",
    "        \n",
    "save_gen([df_imbd_train_BBoW, df_imbd_val_BBoW, df_imbd_test_BBoW], \"BBoW\", \"IMBD\")\n",
    "save_gen([df_yelp_train_BBoW, df_yelp_val_BBoW, df_yelp_test_BBoW], \"BBoW\", \"yelp\")\n",
    "save_gen([df_imbd_train_FBoW, df_imbd_val_FBoW, df_imbd_test_FBoW], \"FBoW\", \"IMBD\")\n",
    "save_gen([df_yelp_train_FBoW, df_yelp_val_FBoW, df_yelp_test_FBoW], \"FBoW\", \"yelp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_train_BBoW = np.loadtxt(path_to_gen + \"IMBD-train-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_train_FBoW = np.loadtxt(path_to_gen + \"IMBD-train-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_train_BBoW = np.loadtxt(path_to_gen + \"yelp-train-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_train_FBoW = np.loadtxt(path_to_gen + \"yelp-train-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_test_BBoW = np.loadtxt(path_to_gen + \"IMBD-test-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_test_FBoW = np.loadtxt(path_to_gen + \"IMBD-test-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_test_BBoW = np.loadtxt(path_to_gen + \"yelp-test-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_test_FBoW = np.loadtxt(path_to_gen + \"yelp-test-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_val_BBoW = np.loadtxt(path_to_gen + \"IMBD-valid-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imbd_val_FBoW = np.loadtxt(path_to_gen + \"IMBD-valid-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_val_BBoW = np.loadtxt(path_to_gen + \"yelp-valid-BBoW.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_val_FBoW = np.loadtxt(path_to_gen + \"yelp-valid-FBoW.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Using data from **yelp** created with **BBoW** only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_yelp_train_BBoW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f156190ac5e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_yelp_train_BBoW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_yelp_train_BBoW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_yelp_val_BBoW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_yelp_val_BBoW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_yelp_train_BBoW' is not defined"
     ]
    }
   ],
   "source": [
    "x_tr = np.nan_to_num(df_yelp_train_BBoW[:,:-1])\n",
    "y_tr = df_yelp_train_BBoW[:,-1]\n",
    "\n",
    "x_val = np.nan_to_num(df_yelp_val_BBoW[:,:-1])\n",
    "y_val = df_yelp_val_BBoW[:,-1]\n",
    "\n",
    "x_test = np.nan_to_num(df_yelp_test_BBoW[:,:-1])\n",
    "y_test = df_yelp_test_BBoW[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_random_clf(x_tr, y_tr, x_test, y_test, r = 1234):\n",
    "    clf = DummyClassifier(strategy = 'uniform', random_state = r)\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    preds = clf.predict(x_test)\n",
    "    f1 = metrics.f1_score(y_test, preds, average = 'micro')\n",
    "    return f1\n",
    "    \n",
    "def performance_majority_classifier(x_tr, y_tr, x_test, y_test, r = 1234):\n",
    "    most_common_val = stats.mode(y_tr).mode[0]\n",
    "    preds = np.full((y_test.shape), most_common_val)\n",
    "    f1 = metrics.f1_score(y_test, preds, average = 'micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_random = performance_random_clf(x_tr, y_tr, x_test, y_test)\n",
    "baseline_majority = performance_majority_classifier(x_tr, y_tr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance for the random classifier on the Yelp reviews dataset created with BBoW is 0.1975.\n",
      "The performance for the majority classifier on the Yelp reviews dataset created with BBoW is 0.351.\n"
     ]
    }
   ],
   "source": [
    "print(\"The performance for the random classifier on the Yelp \" + \n",
    "      \"reviews dataset created with BBoW is %s.\" % baseline_random)\n",
    "print(\"The performance for the majority classifier on the Yelp \" +\n",
    "      \"reviews dataset created with BBoW is %s.\" % baseline_majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fine_tune = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_bernoulli_naive_bayes(x_tr, y_tr, x_val, y_val, number_of_model, alphas):\n",
    "    all_as = random.choices(list(np.linspace(alphas[0],\n",
    "                                             alphas[1],\n",
    "                                             number_of_model*100, endpoint=True)),\n",
    "                            k=number_of_model)\n",
    "    f1_scores = []\n",
    "    best_model = None\n",
    "    for a in tqdm(all_as):\n",
    "        model = BernoulliNB(alpha = a)\n",
    "        model.fit(x_tr, y_tr)\n",
    "        preds = model.predict(x_val)\n",
    "        cur_f1 = metrics.f1_score(y_val, preds, average = 'micro')\n",
    "        f1_scores.append(cur_f1)\n",
    "        if cur_f1 == max(f1_scores):\n",
    "            best_model = model\n",
    "    print(\"The best f1 score is:\", max(f1_scores))\n",
    "    print(\"The alpha is set to:\", best_model.get_params()['alpha'])\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_decision_tree_classifier(x_tr, y_tr, x_val, y_val,\n",
    "                                       number_of_model, max_depths,\n",
    "                                       min_samples_split, min_samples_leaf):\n",
    "    \n",
    "    all_md = random.choices(list(np.linspace(max_depths[0], max_depths[1],\n",
    "                                             number_of_model*100, endpoint=True)),\n",
    "                            k=number_of_model)\n",
    "    \n",
    "    all_mss = random.choices(list(np.linspace(min_samples_split[0], min_samples_split[1],\n",
    "                                              number_of_model*100, endpoint=True)),\n",
    "                             k=number_of_model)\n",
    "\n",
    "    all_msl = random.choices(list(np.linspace(min_samples_leaf[0], min_samples_leaf[1],\n",
    "                                              number_of_model*100, endpoint=True)),\n",
    "                             k=number_of_model)\n",
    "\n",
    "    f1_scores = []\n",
    "    best_model = None\n",
    "    for md, mss, msl in tqdm(zip(all_md, all_mss, all_msl), total=number_of_model):\n",
    "        model = DecisionTreeClassifier(max_depth=md, min_samples_split=mss, min_samples_leaf=msl)\n",
    "        model.fit(x_tr, y_tr)\n",
    "        preds = model.predict(x_val)\n",
    "        cur_f1 = metrics.f1_score(y_val, preds, average = 'micro')\n",
    "        f1_scores.append(cur_f1)\n",
    "        if cur_f1 == max(f1_scores):\n",
    "            best_model = model\n",
    "    print(\"The best f1 score is:\", max(f1_scores))\n",
    "    print(\"The max depth is set to:\", best_model.get_params()['max_depth'])\n",
    "    print(\"The min samples split is set to:\", best_model.get_params()['min_samples_split'])\n",
    "    print(\"The min samples leaf is set to:\", best_model.get_params()['min_samples_leaf'])\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_linear_SVM(x_tr, y_tr, x_val, y_val,\n",
    "                         number_of_model, cs, gammas):\n",
    "    all_c = random.choices(list(np.linspace(cs[0], cs[1],\n",
    "                                            number_of_model*100, endpoint=True)), \n",
    "                           k=number_of_model)\n",
    "    \n",
    "    all_g = random.choices(list(np.linspace(gammas[0], gammas[1],\n",
    "                                            number_of_model*100, endpoint=True)), \n",
    "                           k=number_of_model)\n",
    "    f1_scores = []\n",
    "    best_model = None\n",
    "    for c, gamma in tqdm(zip(all_c, all_g), total=number_of_model):\n",
    "        model = svm.SVC(C=c, gamma=gamma)\n",
    "        model.fit(x_tr, y_tr)\n",
    "        preds = model.predict(x_val)\n",
    "        cur_f1 = metrics.f1_score(y_val, preds, average = 'micro')\n",
    "        f1_scores.append(cur_f1)\n",
    "        if cur_f1 == max(f1_scores):\n",
    "            best_model = model\n",
    "    print(\"The best f1 score is:\", max(f1_scores))\n",
    "    print(\"The c is set to:\", best_model.get_params()['C'])\n",
    "    print(\"The gamma is set to:\", best_model.get_params()['gamma'])\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bnb = fine_tune_bernoulli_naive_bayes(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                                            [0, 1])\n",
    "model_dtc = fine_tune_decision_tree_classifier(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                                               [1, 32], [0.1, 1.0], [0.1, 0.5])\n",
    "model_lsvm = fine_tune_linear_SVM(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                                  [0.001, 10], [0.001, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = np.nan_to_num(df_yelp_train_FBoW[:,:-1])\n",
    "y_tr = df_yelp_train_FBoW[:,-1]\n",
    "\n",
    "x_val = np.nan_to_num(df_yelp_val_FBoW[:,:-1])\n",
    "y_val = df_yelp_val_FBoW[:,-1]\n",
    "\n",
    "x_test = np.nan_to_num(df_yelp_test_FBoW[:,:-1])\n",
    "y_test = df_yelp_test_FBoW[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_gaussian_naive_bayes(x_tr, y_tr, x_val, y_val, number_of_model, vars_smoothing):\n",
    "    all_vs = random.choices(list(np.linspace(vars_smoothing[0],\n",
    "                                             vars_smoothing[1],\n",
    "                                             number_of_model*100, endpoint=True)),\n",
    "                            k=number_of_model)\n",
    "    f1_scores = []\n",
    "    best_model = None\n",
    "    for vs in tqdm(all_vs):\n",
    "        model = sklearn.naive_bayes.GaussianNB(priors=None, var_smoothing=vs)\n",
    "        model.fit(x_tr, y_tr)\n",
    "        preds = model.predict(x_val)\n",
    "        cur_f1 = metrics.f1_score(y_val, preds, average = 'micro')\n",
    "        f1_scores.append(cur_f1)\n",
    "        if cur_f1 == max(f1_scores):\n",
    "            best_model = model\n",
    "    print(\"The best f1 score is:\", max(f1_scores))\n",
    "    print(\"The alpha is set to:\", best_model.get_params()['var_smoothing'])\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa5722306fd495cacd2d31efc53916c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The best f1 score is: 0.259\n",
      "The alpha is set to: 0.00104020814057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e13f4e20b5545b18b58fc2402e89bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_gnb = fine_tune_gaussian_naive_bayes(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                               [1e-10, 1e-1])\n",
    "\n",
    "model_dtc = fine_tune_decision_tree_classifier(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                                               [1, 32], [0.1, 1.0], [0.1, 0.5])\n",
    "model_lsvm = fine_tune_linear_SVM(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                                  [0.001, 10], [0.001, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = np.nan_to_num(df_imbd_train_BBoW[:,:-1])\n",
    "y_tr = df_yelp_train_BBoW[:,-1]\n",
    "\n",
    "x_val = np.nan_to_num(df_imbd_val_BBoW[:,:-1])\n",
    "y_val = df_yelp_val_BBoW[:,-1]\n",
    "\n",
    "x_test = np.nan_to_num(df_imbd_test_BBoW[:,:-1])\n",
    "y_test = df_yelp_test_BBoW[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_random = performance_random_clf(x_tr, y_tr, x_test, y_test)\n",
    "baseline_majority = performance_majority_classifier(x_tr, y_tr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The performance for the random classifier on the Yelp \" + \n",
    "      \"reviews dataset created with BBoW is %s.\" % baseline_random)\n",
    "print(\"The performance for the majority classifier on the Yelp \" +\n",
    "      \"reviews dataset created with BBoW is %s.\" % baseline_majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bnb = fine_tune_bernoulli_naive_bayes(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                                            [0, 1])\n",
    "model_dtc = fine_tune_decision_tree_classifier(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                                               [1, 32], [0.1, 1.0], [0.1, 0.5])\n",
    "model_lsvm = fine_tune_linear_SVM(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                                  [0.001, 10], [0.001, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = np.nan_to_num(df_imbd_train_FBoW[:,:-1])\n",
    "y_tr = df_yelp_train_FBoW[:,-1]\n",
    "\n",
    "x_val = np.nan_to_num(df_imbd_val_FBoW[:,:-1])\n",
    "y_val = df_yelp_val_FBoW[:,-1]\n",
    "\n",
    "x_test = np.nan_to_num(df_imbd_test_FBoW[:,:-1])\n",
    "y_test = df_yelp_test_FBoW[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnb = fine_tune_gaussian_naive_bayes(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                               [1e-10, 1e-1])\n",
    "\n",
    "model_dtc = fine_tune_decision_tree_classifier(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                                               [1, 32], [0.1, 1.0], [0.1, 0.5])\n",
    "model_lsvm = fine_tune_linear_SVM(x_tr, y_tr, x_val, y_val, n_fine_tune,\n",
    "                                  [0.001, 10], [0.001, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
