{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import string\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../data/\"\n",
    "\n",
    "# paht to imbd\n",
    "imbd_train = \"IMDB-train.txt\"\n",
    "imbd_val = \"IMDB-valid.txt\"\n",
    "imbd_test = \"IMDB-test.txt\"\n",
    "\n",
    "# paht to yelp\n",
    "yelp_train = \"yelp-train.txt\"\n",
    "yelp_val = \"yelp-valid.txt\"\n",
    "yelp_test = \"yelp-test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data as df\n",
    "df_imbd_train = pd.read_csv(path_to_data + yelp_train, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_imbd_test = pd.read_csv(path_to_data + yelp_test, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_imbd_val = pd.read_csv(path_to_data + yelp_val, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "\n",
    "df_yelp_train = pd.read_csv(path_to_data + yelp_train, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_yelp_test = pd.read_csv(path_to_data + yelp_test, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})\n",
    "df_yelp_val = pd.read_csv(path_to_data + yelp_val, sep=\"\\t\",\n",
    "                            header=None).rename(columns={0: \"review\", 1: \"class\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count frequency of normalized x\n",
    "def normalize_df(e):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    normalizer = lambda x: x.lower().translate(translator) # lower and remove punctuation\n",
    "    return list(filter(None, ' '.join(list(map(normalizer, np.array(e.review)))).split(' ')))\n",
    "\n",
    "def normalize_str(e):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    normalizer = lambda x: x.lower().translate(translator) # lower and remove punctuation\n",
    "    return list(filter(None, list(map(normalizer, e.split(' ')))))\n",
    "    \n",
    "    \n",
    "def count_word_frequency(words):\n",
    "    occurence = {}\n",
    "    for w in words:\n",
    "        if w in occurence:\n",
    "            occurence[w] += 1\n",
    "        else:\n",
    "            occurence[w] = 1\n",
    "    return occurence\n",
    "\n",
    "def get_most_n_frequent(data, n):\n",
    "    normed = normalize_df(data)\n",
    "    count_dict = count_word_frequency(normed)\n",
    "    n_sorted_words = (sorted(count_dict.items(), key=lambda kv: kv[1], reverse = True)[:n])\n",
    "    return [k for k,v in n_sorted_words]\n",
    "    \n",
    "def gen_BBoW(data, data_train = None, n = 10000, bin = True):\n",
    "    most_freq = []\n",
    "    df_vector = pd.DataFrame(columns=['review', 'class'])\n",
    "\n",
    "    # check if we use the data to generate the train or not\n",
    "    if data_train is None:\n",
    "        most_freq = get_most_n_frequent(data, n)\n",
    "    else:\n",
    "        most_freq = get_most_n_frequent(data_train, n)\n",
    "    \n",
    "    for review, class_id in tqdm(zip(data.review, data['class']), total = len(data.review)):\n",
    "        vector = np.zeros(n)        \n",
    "        for word in normalize_str(review):\n",
    "            if word in most_freq:\n",
    "                i = most_freq.index(word)\n",
    "                if bin:\n",
    "                    vector[i] = 1\n",
    "                else:\n",
    "                    vector[i] += 1\n",
    "        sum_ = sum(vector)\n",
    "        if not bin:\n",
    "            vector = [float(e/sum_) for e in vector]\n",
    "        df_vector = df_vector.append({'review': vector, 'class': class_id}, ignore_index=True)\n",
    "    return df_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa86550d24944aa7a393e7820d12d7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# binary bag-of-words representation\n",
    "df_imbd_train_BBoW = gen_BBoW(df_imbd_train, df_imbd_train, bin = True)\n",
    "df_yelp_train_BBoW = gen_BBoW(df_yelp_train, df_yelp_train, bin = True)\n",
    "df_imbd_test_BBoW = gen_BBoW(df_imbd_test, df_imbd_train, bin = True)\n",
    "df_yelp_test_BBoW = gen_BBoW(df_yelp_test, df_yelp_train, bin = True)\n",
    "df_imbd_val_BBoW = gen_BBoW(df_imbd_val, df_imbd_train, bin = True)\n",
    "df_yelp_val_BBoW = gen_BBoW(df_yelp_val, df_yelp_train, bin = True)\n",
    "\n",
    "# frequency bag-of-words representation\n",
    "df_imbd_train_FBoW = gen_BBoW(df_imbd_train, df_imbd_train, bin = False)\n",
    "df_yelp_train_FBoW = gen_BBoW(df_yelp_train, df_yelp_train, bin = False)\n",
    "df_imbd_test_FBoW = gen_BBoW(df_imbd_test, df_imbd_train, bin = False)\n",
    "df_yelp_test_FBoW = gen_BBoW(df_yelp_test, df_yelp_train, bin = False)\n",
    "df_imbd_val_FBoW = gen_BBoW(df_imbd_val, df_imbd_train, bin = False)\n",
    "df_yelp_val_FBoW = gen_BBoW(df_yelp_val, df_yelp_train, bin = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_yelp_test_FBoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
