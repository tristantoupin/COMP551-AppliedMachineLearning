{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 12345\n",
    "datasets_path = \"../Datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing data in dataframes, and dropping a random column with unknown values in it, plus renaming the columns\n",
    "df_train = pd.read_csv(datasets_path + \n",
    "                       \"Dataset_2_train.csv\", \n",
    "                       header = None).drop(labels=2, axis=1).rename(index=str, columns={0: \"x\", 1: \"y\"})\n",
    "df_test = pd.read_csv(datasets_path + \n",
    "                      \"Dataset_2_test.csv\", \n",
    "                      header = None).drop(labels=2, axis=1).rename(index=str, columns={0: \"x\", 1: \"y\"})\n",
    "df_val = pd.read_csv(datasets_path + \n",
    "                     \"Dataset_2_valid.csv\", \n",
    "                     header = None).drop(labels=2, axis=1).rename(index=str, columns={0: \"x\", 1: \"y\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_fn_coeffs = np.random.rand(2)\n",
    "patience = 500  # To measure learning stature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(xs, ys, w_i):\n",
    "    loss = 0\n",
    "    for x,y in zip(xs,ys):\n",
    "        loss += (compute_fn(regression_fn_coeffs, x) - y) * (x**w_i)\n",
    "    return loss/(len(xs))\n",
    "\n",
    "def compute_fn(coeffs, x):\n",
    "    y = 0\n",
    "    for order, c in enumerate(coeffs):\n",
    "        y += (x**order) * c\n",
    "    return y\n",
    "\n",
    "def compute_mse(xs, ys):\n",
    "    mse = 0\n",
    "    for x,y in zip(xs,ys):\n",
    "        mse += (compute_fn(regression_fn_coeffs, x) - y)**2\n",
    "    return mse/len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, df_val, learning_rate = 1e-6):\n",
    "    # train and valication data\n",
    "    xs, ys = df_train.x.values, df_train.x.values\n",
    "    x_val, y_val = df_val.x.values, df_val.x.values\n",
    "    # rolling window over MSE to stop when stature\n",
    "    rolling_mse_val = deque(maxlen=patience)\n",
    "    all_mse_val, all_mse_tr = [], []\n",
    "    epoch = 0\n",
    "    \n",
    "    # Training loop, stoping based on rolling_mse\n",
    "    while True:\n",
    "        for c_i, c in enumerate(regression_fn_coeffs):\n",
    "            # update weights\n",
    "            regression_fn_coeffs[c_i] -= learning_rate * get_loss(xs, ys, c_i)\n",
    "\n",
    "        # get epoch MSE for validation and train\n",
    "        current_mse_val, current_mse_tr = compute_mse(x_val, y_val), compute_mse(xs, ys)\n",
    "        \n",
    "        # add MSEs to lists\n",
    "        all_mse_val.append(current_mse_val)\n",
    "        all_mse_tr.append(current_mse_tr)\n",
    "        rolling_mse_val.append(current_mse_val)\n",
    "        \n",
    "        # evaluate model every 1000 steps and stop if stature\n",
    "        if epoch % patience == 0 and epoch > patience:\n",
    "            print(\"Mean Squared Error at epoch %s is %s\" % (epoch, current_mse_val))\n",
    "            if sum(rolling_mse_val)/len(rolling_mse_val) < rolling_mse_val[-1]:\n",
    "                # Not learning anymore, returning all mse\n",
    "                return all_mse_tr, all_mse_val\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error at epoch 1000 is 0.010385531778\n",
      "Mean Squared Error at epoch 2000 is 0.00126101726935\n",
      "Mean Squared Error at epoch 3000 is 0.000153113445538\n",
      "Mean Squared Error at epoch 4000 is 1.85911230356e-05\n",
      "Mean Squared Error at epoch 5000 is 2.25734490208e-06\n",
      "Mean Squared Error at epoch 6000 is 2.74088122444e-07\n",
      "Mean Squared Error at epoch 7000 is 3.32799382122e-08\n",
      "Mean Squared Error at epoch 8000 is 4.04086932895e-09\n",
      "Mean Squared Error at epoch 9000 is 4.90644688987e-10\n",
      "Mean Squared Error at epoch 10000 is 5.95743616641e-11\n",
      "Mean Squared Error at epoch 11000 is 7.23355342001e-12\n",
      "Mean Squared Error at epoch 12000 is 8.78302236845e-13\n",
      "Mean Squared Error at epoch 13000 is 1.06643965012e-13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-31db2424670f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_mse_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_mse_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-de54de1c01f2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(df_train, df_val, learning_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression_fn_coeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mregression_fn_coeffs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# get epoch MSE for validation and train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b7ab1305a427>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(xs, ys, w_i)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompute_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression_fn_coeffs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mw_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_mse_train, all_mse_val = train(df_train, df_val, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(all_mse_train)), all_mse_train, 'ro', range(len(all_mse_val)), all_mse_val, 'bo')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
