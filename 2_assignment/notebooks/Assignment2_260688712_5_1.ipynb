{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "gen_data_path = \"generated/\"\n",
    "c1_m1_file = \"DS2_c1_m1.txt\" # positive \n",
    "c1_m2_file = \"DS2_c1_m2.txt\" # positive \n",
    "c1_m3_file = \"DS2_c1_m3.txt\" # positive \n",
    "c2_m1_file = \"DS2_c2_m1.txt\" # negative\n",
    "c2_m2_file = \"DS2_c2_m2.txt\" # negative\n",
    "c2_m3_file = \"DS2_c2_m3.txt\" # negative\n",
    "cov1_file = \"DS2_Cov1.txt\"\n",
    "cov2_file = \"DS2_Cov2.txt\"\n",
    "cov3_file = \"DS2_Cov3.txt\"\n",
    "\n",
    "probability_mixture = [0.1,0.42,0.48]\n",
    "num_class = 2\n",
    "num_features = 20\n",
    "num_obs = 2000\n",
    "train_val_test_sizes = [0.6, 0.2, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(feat, file_path, squeeze = True):\n",
    "    if squeeze:\n",
    "        return np.squeeze(pd.read_csv(file_path, header = None).drop(columns = feat).values, axis = 0)\n",
    "    else:\n",
    "        return pd.read_csv(file_path, header = None).drop(columns = feat).values\n",
    "    \n",
    "def get_x_y_values(dataset):\n",
    "    return dataset.drop('class', axis = 1).values, dataset['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(gen_data_path + 'DS2', index_col = 'Unnamed: 0')\n",
    "df_train = pd.read_csv(gen_data_path + 'DS2_train', index_col = 'Unnamed: 0')\n",
    "test_x, test_y = get_x_y_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    return 1 / (1 + math.exp(-a))\n",
    "\n",
    "def set_coeff(data):\n",
    "    neg_xs = np.array(df_train.loc[df_train['class'] == 0].drop('class', axis = 1))\n",
    "    pos_xs = np.array(df_train.loc[df_train['class'] == 1].drop('class', axis = 1))\n",
    "    all_xs = np.array(df_train.drop('class', axis = 1))\n",
    "    \n",
    "    # get means and covariance metrix\n",
    "    cov = np.cov(all_xs.T)\n",
    "    m0 = np.mean(neg_xs, axis = 0)\n",
    "    m1 = np.mean(pos_xs, axis = 0)\n",
    "    \n",
    "    # calculate w and w0\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    w = np.matmul(inv_cov, (m0-m1))\n",
    "    w0_0 = -0.5 * np.matmul(m0.T, np.matmul(inv_cov, m0))\n",
    "    w0_1 = 0.5 * np.matmul(m1.T, np.matmul(inv_cov, m1))\n",
    "    w0_2 = np.log((len(neg_xs)/len(all_xs))/(len(pos_xs)/len(all_xs)))\n",
    "    \n",
    "    # adding b/c 50/50 percent chances\n",
    "    w0 = w0_0 + w0_1 + w0_2\n",
    "    return w, w0\n",
    "\n",
    "def eval_x(x):\n",
    "    a = np.matmul(w_glob, x) + w0_glob\n",
    "    return round(1 - sigmoid(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_glob, w0_glob = set_coeff(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(data_x, data_y):\n",
    "    TN, TP, FN, FP = 0, 0, 0, 0\n",
    "    for x, y in zip(data_x, data_y):\n",
    "        y_pred = eval_x(x)\n",
    "        if y_pred == y:\n",
    "            if y_pred:\n",
    "                TP += 1\n",
    "            else: \n",
    "                TN += 1\n",
    "        else: \n",
    "            if y_pred:\n",
    "                FP += 1\n",
    "            else: \n",
    "                FN += 1\n",
    "    \n",
    "    accuracy = (TN + TP)/len(data_y)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F_measure = (2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    return accuracy, precision, recall, F_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, F_measure = test_model(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.485.\n",
      "The precision is: 0.48292682926829267.\n",
      "The recall is: 0.49748743718592964.\n",
      "The F-measure is: 0.49009900990099003.\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy is: %s.\" % (accuracy))\n",
    "print(\"The precision is: %s.\" % (precision))\n",
    "print(\"The recall is: %s.\" % (recall))\n",
    "print(\"The F-measure is: %s.\" % (F_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The learnt w0 coefficiants is: 0.0186337247932.\n",
      "The learnt w coefficiants are: [ 0.00862355 -0.03733938 -0.11616578  0.05516113 -0.06615171 -0.09799603\n",
      "  0.00843698 -0.11474018  0.0557585   0.00328878 -0.04304396 -0.02190424\n",
      " -0.0071664   0.11735962 -0.02379976  0.05307851  0.023536    0.06232784\n",
      "  0.00127837  0.11328722].\n"
     ]
    }
   ],
   "source": [
    "print(\"The learnt w0 coefficiants is: %s.\" % w0_glob)\n",
    "print(\"The learnt w coefficiants are: %s.\" % w_glob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
