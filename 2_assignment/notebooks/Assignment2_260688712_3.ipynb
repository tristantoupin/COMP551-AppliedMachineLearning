{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "gen_data_path = \"generated/\"\n",
    "df_tr_file = \"DS1_train\"\n",
    "df_test_file = \"DS1\"\n",
    "df_val_file = \"DS1_val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(gen_data_path + df_test_file, index_col = 'Unnamed: 0')\n",
    "df_val = pd.read_csv(gen_data_path + df_val_file, index_col = 'Unnamed: 0')\n",
    "df_tr = pd.read_csv(gen_data_path + df_tr_file, index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_values(dataset):\n",
    "    return dataset.drop('class', axis = 1).values, dataset['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = get_x_y_values(df_test)\n",
    "val_x, val_y = get_x_y_values(df_val)\n",
    "train_x, train_y = get_x_y_values(df_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(a, b):\n",
    "    return distance.cdist(a, b, metric='euclidean')\n",
    "\n",
    "def knn(k, xs, ys):\n",
    "    TN, TP, FN, FP = 0, 0, 0, 0\n",
    "    distances_indexes = np.array([])\n",
    "    for x, y in zip(xs, ys):\n",
    "        d = get_dist([x], train_x).flatten().flatten().argsort()[:k]\n",
    "        distances_indexes = np.append(distances_indexes, d)\n",
    "        \n",
    "        # find the class of val_x based on k-nearest neighbors\n",
    "        classes = [(train_y[int(i)]) for i in distances_indexes]\n",
    "        y_pred = int(round(sum(classes)/len(classes)))\n",
    "        \n",
    "        if y_pred == y:\n",
    "            if y_pred:\n",
    "                TP += 1\n",
    "            else: \n",
    "                TN += 1\n",
    "        else: \n",
    "            if y_pred:\n",
    "                FP += 1\n",
    "            else: \n",
    "                FN += 1\n",
    "            \n",
    "    accuracy = (TN + TP)/len(ys)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F_measure = (2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    return np.array([accuracy, precision, recall, F_measure])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a99dc7b57d482a990ca14c47486c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = np.array([])\n",
    "# trying k values ranging from [1, 50]\n",
    "result = knn(1, val_x, val_y)\n",
    "for k in tqdm(range(2,101)):\n",
    "    result = np.vstack([result, knn(k, val_x, val_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 1, the accuracy: 0.5300, precision: 0.5095, recall: 0.9590 and F-measure: 0.6655\n",
      "For k = 2, the accuracy: 0.5200, precision: 0.5041, recall: 0.9385 and F-measure: 0.6559\n",
      "For k = 3, the accuracy: 0.5525, precision: 0.5312, recall: 0.6974 and F-measure: 0.6031\n",
      "For k = 4, the accuracy: 0.5350, precision: 0.5150, recall: 0.7949 and F-measure: 0.6250\n",
      "For k = 5, the accuracy: 0.5425, precision: 0.5214, recall: 0.7487 and F-measure: 0.6147\n",
      "For k = 6, the accuracy: 0.5500, precision: 0.5273, recall: 0.7436 and F-measure: 0.6170\n",
      "For k = 7, the accuracy: 0.5475, precision: 0.5255, recall: 0.7385 and F-measure: 0.6141\n",
      "For k = 8, the accuracy: 0.4950, precision: 0.4737, recall: 0.3231 and F-measure: 0.3841\n",
      "For k = 9, the accuracy: 0.5150, precision: 0.5022, recall: 0.5897 and F-measure: 0.5425\n",
      "For k = 10, the accuracy: 0.5700, precision: 0.5392, recall: 0.8103 and F-measure: 0.6475\n",
      "For k = 11, the accuracy: 0.5450, precision: 0.5302, recall: 0.5846 and F-measure: 0.5561\n",
      "For k = 12, the accuracy: 0.5800, precision: 0.5730, recall: 0.5436 and F-measure: 0.5579\n",
      "For k = 13, the accuracy: 0.5750, precision: 0.5641, recall: 0.5641 and F-measure: 0.5641\n",
      "For k = 14, the accuracy: 0.5650, precision: 0.5436, recall: 0.6718 and F-measure: 0.6009\n",
      "For k = 15, the accuracy: 0.5725, precision: 0.5435, recall: 0.7692 and F-measure: 0.6369\n",
      "For k = 16, the accuracy: 0.5625, precision: 0.5323, recall: 0.8462 and F-measure: 0.6535\n",
      "For k = 17, the accuracy: 0.5475, precision: 0.5246, recall: 0.7641 and F-measure: 0.6221\n",
      "For k = 18, the accuracy: 0.5675, precision: 0.5478, recall: 0.6462 and F-measure: 0.5929\n",
      "For k = 19, the accuracy: 0.5800, precision: 0.5529, recall: 0.7231 and F-measure: 0.6267\n",
      "For k = 20, the accuracy: 0.5625, precision: 0.5370, recall: 0.7436 and F-measure: 0.6237\n",
      "For k = 21, the accuracy: 0.5525, precision: 0.5267, recall: 0.8103 and F-measure: 0.6384\n",
      "For k = 22, the accuracy: 0.5250, precision: 0.5086, recall: 0.7590 and F-measure: 0.6091\n",
      "For k = 23, the accuracy: 0.5325, precision: 0.5135, recall: 0.7795 and F-measure: 0.6191\n",
      "For k = 24, the accuracy: 0.5300, precision: 0.5112, recall: 0.8205 and F-measure: 0.6299\n",
      "For k = 25, the accuracy: 0.5050, precision: 0.4960, recall: 0.9590 and F-measure: 0.6538\n",
      "For k = 26, the accuracy: 0.5100, precision: 0.4985, recall: 0.8667 and F-measure: 0.6330\n",
      "For k = 27, the accuracy: 0.5375, precision: 0.5231, recall: 0.5795 and F-measure: 0.5499\n",
      "For k = 28, the accuracy: 0.5475, precision: 0.5310, recall: 0.6154 and F-measure: 0.5701\n",
      "For k = 29, the accuracy: 0.5450, precision: 0.5230, recall: 0.7590 and F-measure: 0.6192\n",
      "For k = 30, the accuracy: 0.5275, precision: 0.5099, recall: 0.7897 and F-measure: 0.6197\n",
      "For k = 31, the accuracy: 0.5325, precision: 0.5155, recall: 0.6821 and F-measure: 0.5872\n",
      "For k = 32, the accuracy: 0.5400, precision: 0.5242, recall: 0.6103 and F-measure: 0.5640\n",
      "For k = 33, the accuracy: 0.5450, precision: 0.5236, recall: 0.7385 and F-measure: 0.6128\n",
      "For k = 34, the accuracy: 0.5400, precision: 0.5172, recall: 0.8462 and F-measure: 0.6420\n",
      "For k = 35, the accuracy: 0.5475, precision: 0.5315, recall: 0.6051 and F-measure: 0.5659\n",
      "For k = 36, the accuracy: 0.5775, precision: 0.5684, recall: 0.5538 and F-measure: 0.5610\n",
      "For k = 37, the accuracy: 0.5350, precision: 0.5319, recall: 0.3846 and F-measure: 0.4464\n",
      "For k = 38, the accuracy: 0.5375, precision: 0.5490, recall: 0.2872 and F-measure: 0.3771\n",
      "For k = 39, the accuracy: 0.5475, precision: 0.5407, recall: 0.4769 and F-measure: 0.5068\n",
      "For k = 40, the accuracy: 0.5550, precision: 0.5480, recall: 0.4974 and F-measure: 0.5215\n",
      "For k = 41, the accuracy: 0.5575, precision: 0.5441, recall: 0.5692 and F-measure: 0.5564\n",
      "For k = 42, the accuracy: 0.5525, precision: 0.5494, recall: 0.4564 and F-measure: 0.4986\n",
      "For k = 43, the accuracy: 0.5500, precision: 0.5547, recall: 0.3897 and F-measure: 0.4578\n",
      "For k = 44, the accuracy: 0.5300, precision: 0.5455, recall: 0.2154 and F-measure: 0.3088\n",
      "For k = 45, the accuracy: 0.5375, precision: 0.5625, recall: 0.2308 and F-measure: 0.3273\n",
      "For k = 46, the accuracy: 0.5375, precision: 0.5410, recall: 0.3385 and F-measure: 0.4164\n",
      "For k = 47, the accuracy: 0.5275, precision: 0.5300, recall: 0.2718 and F-measure: 0.3593\n",
      "For k = 48, the accuracy: 0.5450, precision: 0.5699, recall: 0.2718 and F-measure: 0.3681\n",
      "For k = 49, the accuracy: 0.5325, precision: 0.5308, recall: 0.3538 and F-measure: 0.4246\n",
      "For k = 50, the accuracy: 0.5775, precision: 0.5670, recall: 0.5641 and F-measure: 0.5656\n",
      "For k = 51, the accuracy: 0.5550, precision: 0.5503, recall: 0.4769 and F-measure: 0.5110\n",
      "For k = 52, the accuracy: 0.5425, precision: 0.5370, recall: 0.4462 and F-measure: 0.4874\n",
      "For k = 53, the accuracy: 0.5525, precision: 0.5494, recall: 0.4564 and F-measure: 0.4986\n",
      "For k = 54, the accuracy: 0.5575, precision: 0.5536, recall: 0.4769 and F-measure: 0.5124\n",
      "For k = 55, the accuracy: 0.5600, precision: 0.5492, recall: 0.5436 and F-measure: 0.5464\n",
      "For k = 56, the accuracy: 0.5575, precision: 0.5441, recall: 0.5692 and F-measure: 0.5564\n",
      "For k = 57, the accuracy: 0.5475, precision: 0.5321, recall: 0.5949 and F-measure: 0.5617\n",
      "For k = 58, the accuracy: 0.5300, precision: 0.5148, recall: 0.6256 and F-measure: 0.5648\n",
      "For k = 59, the accuracy: 0.5450, precision: 0.5302, recall: 0.5846 and F-measure: 0.5561\n",
      "For k = 60, the accuracy: 0.5550, precision: 0.5407, recall: 0.5795 and F-measure: 0.5594\n",
      "For k = 61, the accuracy: 0.5525, precision: 0.5408, recall: 0.5436 and F-measure: 0.5422\n",
      "For k = 62, the accuracy: 0.5575, precision: 0.5421, recall: 0.5949 and F-measure: 0.5672\n",
      "For k = 63, the accuracy: 0.5500, precision: 0.5362, recall: 0.5692 and F-measure: 0.5522\n",
      "For k = 64, the accuracy: 0.5400, precision: 0.5217, recall: 0.6769 and F-measure: 0.5893\n",
      "For k = 65, the accuracy: 0.5400, precision: 0.5244, recall: 0.6051 and F-measure: 0.5619\n",
      "For k = 66, the accuracy: 0.5475, precision: 0.5327, recall: 0.5846 and F-measure: 0.5575\n",
      "For k = 67, the accuracy: 0.5425, precision: 0.5265, recall: 0.6103 and F-measure: 0.5653\n",
      "For k = 68, the accuracy: 0.5450, precision: 0.5279, recall: 0.6308 and F-measure: 0.5748\n",
      "For k = 69, the accuracy: 0.5500, precision: 0.5346, recall: 0.5949 and F-measure: 0.5631\n",
      "For k = 70, the accuracy: 0.5575, precision: 0.5441, recall: 0.5692 and F-measure: 0.5564\n",
      "For k = 71, the accuracy: 0.5575, precision: 0.5474, recall: 0.5333 and F-measure: 0.5403\n",
      "For k = 72, the accuracy: 0.5525, precision: 0.5426, recall: 0.5231 and F-measure: 0.5326\n",
      "For k = 73, the accuracy: 0.5550, precision: 0.5450, recall: 0.5282 and F-measure: 0.5365\n",
      "For k = 74, the accuracy: 0.5500, precision: 0.5381, recall: 0.5436 and F-measure: 0.5408\n",
      "For k = 75, the accuracy: 0.5525, precision: 0.5396, recall: 0.5590 and F-measure: 0.5491\n",
      "For k = 76, the accuracy: 0.5625, precision: 0.5495, recall: 0.5692 and F-measure: 0.5592\n",
      "For k = 77, the accuracy: 0.5600, precision: 0.5459, recall: 0.5795 and F-measure: 0.5622\n",
      "For k = 78, the accuracy: 0.5500, precision: 0.5339, recall: 0.6051 and F-measure: 0.5673\n",
      "For k = 79, the accuracy: 0.5550, precision: 0.5374, recall: 0.6256 and F-measure: 0.5782\n",
      "For k = 80, the accuracy: 0.5500, precision: 0.5299, recall: 0.6821 and F-measure: 0.5964\n",
      "For k = 81, the accuracy: 0.5525, precision: 0.5320, recall: 0.6821 and F-measure: 0.5978\n",
      "For k = 82, the accuracy: 0.5500, precision: 0.5287, recall: 0.7077 and F-measure: 0.6053\n",
      "For k = 83, the accuracy: 0.5450, precision: 0.5238, recall: 0.7333 and F-measure: 0.6111\n",
      "For k = 84, the accuracy: 0.5425, precision: 0.5216, recall: 0.7436 and F-measure: 0.6131\n",
      "For k = 85, the accuracy: 0.5500, precision: 0.5273, recall: 0.7436 and F-measure: 0.6170\n",
      "For k = 86, the accuracy: 0.5375, precision: 0.5180, recall: 0.7385 and F-measure: 0.6089\n",
      "For k = 87, the accuracy: 0.5500, precision: 0.5256, recall: 0.7897 and F-measure: 0.6311\n",
      "For k = 88, the accuracy: 0.5575, precision: 0.5336, recall: 0.7333 and F-measure: 0.6177\n",
      "For k = 89, the accuracy: 0.5225, precision: 0.5083, recall: 0.6256 and F-measure: 0.5609\n",
      "For k = 90, the accuracy: 0.5275, precision: 0.5125, recall: 0.6308 and F-measure: 0.5655\n",
      "For k = 91, the accuracy: 0.5375, precision: 0.5214, recall: 0.6256 and F-measure: 0.5688\n",
      "For k = 92, the accuracy: 0.5525, precision: 0.5370, recall: 0.5949 and F-measure: 0.5645\n",
      "For k = 93, the accuracy: 0.5600, precision: 0.5426, recall: 0.6205 and F-measure: 0.5789\n",
      "For k = 94, the accuracy: 0.5450, precision: 0.5279, recall: 0.6308 and F-measure: 0.5748\n",
      "For k = 95, the accuracy: 0.5575, precision: 0.5405, recall: 0.6154 and F-measure: 0.5755\n",
      "For k = 96, the accuracy: 0.5450, precision: 0.5270, recall: 0.6513 and F-measure: 0.5826\n",
      "For k = 97, the accuracy: 0.5550, precision: 0.5362, recall: 0.6462 and F-measure: 0.5860\n",
      "For k = 98, the accuracy: 0.5600, precision: 0.5434, recall: 0.6103 and F-measure: 0.5749\n",
      "For k = 99, the accuracy: 0.5675, precision: 0.5524, recall: 0.5949 and F-measure: 0.5728\n",
      "For k = 100, the accuracy: 0.5700, precision: 0.5596, recall: 0.5538 and F-measure: 0.5567\n"
     ]
    }
   ],
   "source": [
    "for k, (accuracy, precision, recall, F_measure) in enumerate(result):\n",
    "   print(\"For k = %s, the accuracy: %.4f, \"\n",
    "         \"precision: %.4f, recall: %.4f \"\n",
    "         \"and F-measure: %.4f\" % (k+1, accuracy, precision, recall, F_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1 = np.max(result[:,3])\n",
    "f1_pos = np.where(result[:,3] == max_f1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1 score is 0.665480427046 with k = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"The best f1 score is %s with k = %s\" % (max_f1, f1_pos + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = knn(1, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 1, the accuracy: 0.4775, precision: 0.4917, recall: 0.7255 and F-measure: 0.5861\n"
     ]
    }
   ],
   "source": [
    "print(\"For k = %s, the accuracy: %.4f, \"\n",
    "     \"precision: %.4f, recall: %.4f \"\n",
    "     \"and F-measure: %.4f\" % (f1_pos + 1, test_metrics[0], test_metrics[1], test_metrics[2], test_metrics[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
