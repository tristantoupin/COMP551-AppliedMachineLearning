{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "gen_data_path = \"generated/\"\n",
    "df_tr_file = \"DS2_train\"\n",
    "df_test_file = \"DS2\"\n",
    "df_val_file = \"DS2_val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(gen_data_path + df_test_file, index_col = 'Unnamed: 0')\n",
    "df_val = pd.read_csv(gen_data_path + df_val_file, index_col = 'Unnamed: 0')\n",
    "df_tr = pd.read_csv(gen_data_path + df_tr_file, index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_values(dataset):\n",
    "    return dataset.drop('class', axis = 1).values, dataset['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = get_x_y_values(df_test)\n",
    "val_x, val_y = get_x_y_values(df_val)\n",
    "train_x, train_y = get_x_y_values(df_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(a, b):\n",
    "    return distance.cdist(a, b, metric='euclidean')\n",
    "\n",
    "def knn(k, xs, ys):\n",
    "    TN, TP, FN, FP = 0, 0, 0, 0\n",
    "    distances_indexes = np.array([])\n",
    "    for x, y in zip(xs, ys):\n",
    "        d = get_dist([x], train_x).flatten().flatten().argsort()[:k]\n",
    "        distances_indexes = np.append(distances_indexes, d)\n",
    "        \n",
    "        # find the class of val_x based on k-nearest neighbors\n",
    "        classes = [(train_y[int(i)]) for i in distances_indexes]\n",
    "        y_pred = int(round(sum(classes)/len(classes)))\n",
    "        \n",
    "        if y_pred == y:\n",
    "            if y_pred:\n",
    "                TP += 1\n",
    "            else: \n",
    "                TN += 1\n",
    "        else: \n",
    "            if y_pred:\n",
    "                FP += 1\n",
    "            else: \n",
    "                FN += 1\n",
    "            \n",
    "    accuracy = (TN + TP)/len(ys)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F_measure = (2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    return np.array([accuracy, precision, recall, F_measure])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b712c56eab024d7bac675ea379fd8477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = np.array([])\n",
    "# trying k values ranging from [1, 50]\n",
    "result = knn(1, val_x, val_y)\n",
    "for k in tqdm(range(2,101)):\n",
    "    result = np.vstack([result, knn(k, val_x, val_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 1, the accuracy: 0.4850, precision: 0.4696, recall: 0.2714 and F-measure: 0.3439\n",
      "For k = 2, the accuracy: 0.5150, precision: 0.5110, recall: 0.5829 and F-measure: 0.5446\n",
      "For k = 3, the accuracy: 0.4950, precision: 0.4948, recall: 0.7186 and F-measure: 0.5861\n",
      "For k = 4, the accuracy: 0.5150, precision: 0.5309, recall: 0.2161 and F-measure: 0.3071\n",
      "For k = 5, the accuracy: 0.5000, precision: 0.4986, recall: 0.8894 and F-measure: 0.6390\n",
      "For k = 6, the accuracy: 0.4975, precision: 0.4975, recall: 0.9899 and F-measure: 0.6622\n",
      "For k = 7, the accuracy: 0.4975, precision: 0.4975, recall: 0.9950 and F-measure: 0.6633\n",
      "For k = 8, the accuracy: 0.5000, precision: 0.4987, recall: 0.9899 and F-measure: 0.6633\n",
      "For k = 9, the accuracy: 0.5075, precision: 0.5027, recall: 0.9497 and F-measure: 0.6574\n",
      "For k = 10, the accuracy: 0.5175, precision: 0.5086, recall: 0.8894 and F-measure: 0.6472\n",
      "For k = 11, the accuracy: 0.4975, precision: 0.4975, recall: 0.9899 and F-measure: 0.6622\n",
      "For k = 12, the accuracy: 0.4975, precision: 0.4975, recall: 0.9899 and F-measure: 0.6622\n",
      "For k = 13, the accuracy: 0.5025, precision: 0.5000, recall: 0.9899 and F-measure: 0.6644\n",
      "For k = 14, the accuracy: 0.5000, precision: 0.4987, recall: 0.9799 and F-measure: 0.6610\n",
      "For k = 15, the accuracy: 0.5000, precision: 0.4987, recall: 0.9799 and F-measure: 0.6610\n",
      "For k = 16, the accuracy: 0.5000, precision: 0.4987, recall: 0.9849 and F-measure: 0.6622\n",
      "For k = 17, the accuracy: 0.5000, precision: 0.4987, recall: 0.9749 and F-measure: 0.6599\n",
      "For k = 18, the accuracy: 0.5050, precision: 0.5013, recall: 0.9749 and F-measure: 0.6621\n",
      "For k = 19, the accuracy: 0.5075, precision: 0.5027, recall: 0.9447 and F-measure: 0.6562\n",
      "For k = 20, the accuracy: 0.5025, precision: 0.5000, recall: 0.9146 and F-measure: 0.6465\n",
      "For k = 21, the accuracy: 0.5050, precision: 0.5014, recall: 0.9045 and F-measure: 0.6452\n",
      "For k = 22, the accuracy: 0.5075, precision: 0.5028, recall: 0.9095 and F-measure: 0.6476\n",
      "For k = 23, the accuracy: 0.4975, precision: 0.4970, recall: 0.8241 and F-measure: 0.6200\n",
      "For k = 24, the accuracy: 0.4950, precision: 0.4948, recall: 0.7236 and F-measure: 0.5878\n",
      "For k = 25, the accuracy: 0.5075, precision: 0.5031, recall: 0.8040 and F-measure: 0.6190\n",
      "For k = 26, the accuracy: 0.5175, precision: 0.5088, recall: 0.8693 and F-measure: 0.6419\n",
      "For k = 27, the accuracy: 0.4825, precision: 0.4850, recall: 0.6482 and F-measure: 0.5548\n",
      "For k = 28, the accuracy: 0.5050, precision: 0.5016, recall: 0.7990 and F-measure: 0.6163\n",
      "For k = 29, the accuracy: 0.5175, precision: 0.5094, recall: 0.8191 and F-measure: 0.6281\n",
      "For k = 30, the accuracy: 0.4925, precision: 0.4930, recall: 0.7035 and F-measure: 0.5797\n",
      "For k = 31, the accuracy: 0.5100, precision: 0.5050, recall: 0.7588 and F-measure: 0.6064\n",
      "For k = 32, the accuracy: 0.5075, precision: 0.5031, recall: 0.8141 and F-measure: 0.6219\n",
      "For k = 33, the accuracy: 0.5150, precision: 0.5068, recall: 0.9397 and F-measure: 0.6585\n",
      "For k = 34, the accuracy: 0.5150, precision: 0.5065, recall: 0.9799 and F-measure: 0.6678\n",
      "For k = 35, the accuracy: 0.5325, precision: 0.5165, recall: 0.9447 and F-measure: 0.6679\n",
      "For k = 36, the accuracy: 0.5225, precision: 0.5110, recall: 0.9347 and F-measure: 0.6607\n",
      "For k = 37, the accuracy: 0.5300, precision: 0.5149, recall: 0.9548 and F-measure: 0.6690\n",
      "For k = 38, the accuracy: 0.5200, precision: 0.5093, recall: 0.9598 and F-measure: 0.6655\n",
      "For k = 39, the accuracy: 0.5225, precision: 0.5108, recall: 0.9548 and F-measure: 0.6655\n",
      "For k = 40, the accuracy: 0.5175, precision: 0.5080, recall: 0.9548 and F-measure: 0.6632\n",
      "For k = 41, the accuracy: 0.5100, precision: 0.5039, recall: 0.9749 and F-measure: 0.6644\n",
      "For k = 42, the accuracy: 0.5100, precision: 0.5039, recall: 0.9648 and F-measure: 0.6621\n",
      "For k = 43, the accuracy: 0.5000, precision: 0.4987, recall: 0.9849 and F-measure: 0.6622\n",
      "For k = 44, the accuracy: 0.4975, precision: 0.4975, recall: 0.9899 and F-measure: 0.6622\n",
      "For k = 45, the accuracy: 0.5025, precision: 0.5000, recall: 0.9849 and F-measure: 0.6633\n",
      "For k = 46, the accuracy: 0.5100, precision: 0.5039, recall: 0.9799 and F-measure: 0.6655\n",
      "For k = 47, the accuracy: 0.5100, precision: 0.5039, recall: 0.9799 and F-measure: 0.6655\n",
      "For k = 48, the accuracy: 0.5125, precision: 0.5052, recall: 0.9799 and F-measure: 0.6667\n",
      "For k = 49, the accuracy: 0.5100, precision: 0.5039, recall: 0.9698 and F-measure: 0.6632\n",
      "For k = 50, the accuracy: 0.5000, precision: 0.4987, recall: 0.9799 and F-measure: 0.6610\n",
      "For k = 51, the accuracy: 0.4950, precision: 0.4962, recall: 0.9849 and F-measure: 0.6599\n",
      "For k = 52, the accuracy: 0.4950, precision: 0.4962, recall: 0.9849 and F-measure: 0.6599\n",
      "For k = 53, the accuracy: 0.4925, precision: 0.4949, recall: 0.9849 and F-measure: 0.6588\n",
      "For k = 54, the accuracy: 0.4950, precision: 0.4962, recall: 0.9849 and F-measure: 0.6599\n",
      "For k = 55, the accuracy: 0.4950, precision: 0.4962, recall: 0.9849 and F-measure: 0.6599\n",
      "For k = 56, the accuracy: 0.5000, precision: 0.4987, recall: 0.9849 and F-measure: 0.6622\n",
      "For k = 57, the accuracy: 0.4950, precision: 0.4962, recall: 0.9849 and F-measure: 0.6599\n",
      "For k = 58, the accuracy: 0.4950, precision: 0.4962, recall: 0.9849 and F-measure: 0.6599\n",
      "For k = 59, the accuracy: 0.4975, precision: 0.4974, recall: 0.9799 and F-measure: 0.6599\n",
      "For k = 60, the accuracy: 0.5025, precision: 0.5000, recall: 0.9849 and F-measure: 0.6633\n",
      "For k = 61, the accuracy: 0.5025, precision: 0.5000, recall: 0.9799 and F-measure: 0.6621\n",
      "For k = 62, the accuracy: 0.5000, precision: 0.4987, recall: 0.9799 and F-measure: 0.6610\n",
      "For k = 63, the accuracy: 0.5025, precision: 0.5000, recall: 0.9849 and F-measure: 0.6633\n",
      "For k = 64, the accuracy: 0.5000, precision: 0.4987, recall: 0.9849 and F-measure: 0.6622\n",
      "For k = 65, the accuracy: 0.4900, precision: 0.4937, recall: 0.9849 and F-measure: 0.6577\n",
      "For k = 66, the accuracy: 0.4900, precision: 0.4937, recall: 0.9849 and F-measure: 0.6577\n",
      "For k = 67, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 68, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 69, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 70, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 71, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 72, the accuracy: 0.4900, precision: 0.4937, recall: 0.9849 and F-measure: 0.6577\n",
      "For k = 73, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 74, the accuracy: 0.4950, precision: 0.4962, recall: 0.9849 and F-measure: 0.6599\n",
      "For k = 75, the accuracy: 0.4975, precision: 0.4975, recall: 0.9849 and F-measure: 0.6610\n",
      "For k = 76, the accuracy: 0.5000, precision: 0.4987, recall: 0.9799 and F-measure: 0.6610\n",
      "For k = 77, the accuracy: 0.5050, precision: 0.5013, recall: 0.9799 and F-measure: 0.6633\n",
      "For k = 78, the accuracy: 0.5025, precision: 0.5000, recall: 0.9799 and F-measure: 0.6621\n",
      "For k = 79, the accuracy: 0.5025, precision: 0.5000, recall: 0.9849 and F-measure: 0.6633\n",
      "For k = 80, the accuracy: 0.4950, precision: 0.4962, recall: 0.9849 and F-measure: 0.6599\n",
      "For k = 81, the accuracy: 0.4950, precision: 0.4962, recall: 0.9849 and F-measure: 0.6599\n",
      "For k = 82, the accuracy: 0.4950, precision: 0.4962, recall: 0.9849 and F-measure: 0.6599\n",
      "For k = 83, the accuracy: 0.4925, precision: 0.4949, recall: 0.9849 and F-measure: 0.6588\n",
      "For k = 84, the accuracy: 0.4925, precision: 0.4949, recall: 0.9849 and F-measure: 0.6588\n",
      "For k = 85, the accuracy: 0.4900, precision: 0.4937, recall: 0.9849 and F-measure: 0.6577\n",
      "For k = 86, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 87, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 88, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 89, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 90, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 91, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 92, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 93, the accuracy: 0.4900, precision: 0.4937, recall: 0.9849 and F-measure: 0.6577\n",
      "For k = 94, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 95, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 96, the accuracy: 0.4925, precision: 0.4950, recall: 0.9899 and F-measure: 0.6600\n",
      "For k = 97, the accuracy: 0.4900, precision: 0.4937, recall: 0.9849 and F-measure: 0.6577\n",
      "For k = 98, the accuracy: 0.4900, precision: 0.4937, recall: 0.9849 and F-measure: 0.6577\n",
      "For k = 99, the accuracy: 0.4900, precision: 0.4937, recall: 0.9849 and F-measure: 0.6577\n",
      "For k = 100, the accuracy: 0.4900, precision: 0.4937, recall: 0.9849 and F-measure: 0.6577\n"
     ]
    }
   ],
   "source": [
    "for k, (accuracy, precision, recall, F_measure) in enumerate(result):\n",
    "   print(\"For k = %s, the accuracy: %.4f, \"\n",
    "         \"precision: %.4f, recall: %.4f \"\n",
    "         \"and F-measure: %.4f\" % (k+1, accuracy, precision, recall, F_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1 = np.max(result[:,3])\n",
    "f1_pos = np.where(result[:,3] == max_f1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best f1 score is 0.669014084507 with k = 37\n"
     ]
    }
   ],
   "source": [
    "print(\"The best f1 score is %s with k = %s\" % (max_f1, f1_pos + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = knn(37, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 37, the accuracy: 0.4800, precision: 0.4875, recall: 0.8794 and F-measure: 0.6272\n"
     ]
    }
   ],
   "source": [
    "print(\"For k = %s, the accuracy: %.4f, \"\n",
    "     \"precision: %.4f, recall: %.4f \"\n",
    "     \"and F-measure: %.4f\" % (f1_pos + 1, test_metrics[0], test_metrics[1], test_metrics[2], test_metrics[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
