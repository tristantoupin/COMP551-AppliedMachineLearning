{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "gen_data_path = \"generated/\"\n",
    "c1_m1_file = \"DS2_c1_m1.txt\" # positive \n",
    "c1_m2_file = \"DS2_c1_m2.txt\" # positive \n",
    "c1_m3_file = \"DS2_c1_m3.txt\" # positive \n",
    "c2_m1_file = \"DS2_c2_m1.txt\" # negative\n",
    "c2_m2_file = \"DS2_c2_m2.txt\" # negative\n",
    "c2_m3_file = \"DS2_c2_m3.txt\" # negative\n",
    "cov1_file = \"DS2_Cov1.txt\"\n",
    "cov2_file = \"DS2_Cov2.txt\"\n",
    "cov3_file = \"DS2_Cov3.txt\"\n",
    "\n",
    "probability_mixture = [0.1,0.42,0.48]\n",
    "num_class = 2\n",
    "num_features = 20\n",
    "num_obs = 2000\n",
    "train_val_test_sizes = [0.6, 0.2, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(feat, file_path, squeeze = True):\n",
    "    if squeeze:\n",
    "        return np.squeeze(pd.read_csv(file_path, header = None).drop(columns = feat).values, axis = 0)\n",
    "    else:\n",
    "        return pd.read_csv(file_path, header = None).drop(columns = feat).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(feat, obs, class_, mixture):\n",
    "    # get the matrix\n",
    "    c1_m1 = get_matrix(feat, data_path + c1_m1_file)\n",
    "    c1_m2 = get_matrix(feat, data_path + c1_m2_file)\n",
    "    c1_m3 = get_matrix(feat, data_path + c1_m3_file)\n",
    "    c2_m1 = get_matrix(feat, data_path + c2_m1_file)\n",
    "    c2_m2 = get_matrix(feat, data_path + c2_m2_file)\n",
    "    c2_m3 = get_matrix(feat, data_path + c2_m3_file)\n",
    "\n",
    "    cov1 = get_matrix(feat, data_path + cov1_file, False)\n",
    "    cov2 = get_matrix(feat, data_path + cov2_file, False)\n",
    "    cov3 = get_matrix(feat, data_path + cov3_file, False)\n",
    "    \n",
    "    # generate random data for negative\n",
    "    neg_class_1 = np.random.multivariate_normal(c1_m1, cov1, int(obs*mixture[0]/class_))\n",
    "    neg_class_2 = np.random.multivariate_normal(c1_m2, cov2, int(obs*mixture[1]/class_))\n",
    "    neg_class_3 = np.random.multivariate_normal(c1_m3, cov3, int(obs*mixture[2]/class_))\n",
    "    \n",
    "    # generate random data for positive\n",
    "    pos_class_1 = np.random.multivariate_normal(c2_m1, cov1, int(obs*mixture[0]/class_))\n",
    "    pos_class_2 = np.random.multivariate_normal(c2_m2, cov2, int(obs*mixture[1]/class_))\n",
    "    pos_class_3 = np.random.multivariate_normal(c2_m3, cov3, int(obs*mixture[2]/class_))\n",
    "    \n",
    "    # add the class id\n",
    "    df_1_n = pd.DataFrame(neg_class_1)\n",
    "    df_2_n = pd.DataFrame(neg_class_2)\n",
    "    df_3_n = pd.DataFrame(neg_class_3)\n",
    "    df_1_p = pd.DataFrame(neg_class_1)\n",
    "    df_2_p = pd.DataFrame(pos_class_2)\n",
    "    df_3_p = pd.DataFrame(pos_class_3)\n",
    "    df_1_n['class'], df_2_n['class'], df_3_n['class'] = 0, 0, 0\n",
    "    df_1_p['class'], df_2_p['class'], df_3_p['class'] = 1, 1, 1\n",
    "    \n",
    "    # concat into a single df\n",
    "    return pd.concat([df_1_n, df_2_n, df_3_n, df_1_p, df_2_p, df_3_p], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(num_features, num_obs, num_class, probability_mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_slipt(data, sizes):\n",
    "    # shuffle the data\n",
    "    data = data.sample(frac=1)\n",
    "    \n",
    "    # get split sizes\n",
    "    tr_size = int(sizes[0] * len(data))\n",
    "    val_size = int(sizes[1] * len(data))\n",
    "    test_size = int(sizes[2] * len(data))\n",
    "    \n",
    "    # divide the data\n",
    "    data_tr = data[:tr_size]\n",
    "    data_val = data[tr_size:tr_size + val_size]\n",
    "    data_test = data[-test_size:]\n",
    "    \n",
    "    return data_tr, data_val, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr, df_val, df_test = train_val_test_slipt(df, train_val_test_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(gen_data_path + 'DS2')\n",
    "df_val.to_csv(gen_data_path + 'DS2_val')\n",
    "df_tr.to_csv(gen_data_path + 'DS2_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
